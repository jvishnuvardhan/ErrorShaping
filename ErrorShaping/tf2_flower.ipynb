{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf2_flower.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jElLULrDhQZR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ca323548-6353-4469-de00-9cee3d3bdb49"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install -q tensorflow==2.0.0-beta1\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
        "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.0.0-beta1\n",
            "Eager execution: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9Edhevw7exl6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5b59e62f-d8c3-4317-d5a5-1f0fa27e4f3b"
      },
      "source": [
        "train_dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\"\n",
        "train_dataset_fp = tf.keras.utils.get_file(fname=os.path.basename(train_dataset_url),\n",
        "                                           origin=train_dataset_url)\n",
        "#print(\"Local copy of the dataset file: {}\".format(train_dataset_fp))\n",
        "#!head -n5 {train_dataset_fp}\n",
        "# column order in CSV file\n",
        "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
        "\n",
        "feature_names = column_names[:-1]\n",
        "label_name = column_names[-1]\n",
        "\n",
        "#print(\"Features: {}\".format(feature_names))\n",
        "#print(\"Label: {}\".format(label_name))\n",
        "class_names = ['Iris setosa', 'Iris versicolor', 'Iris virginica']\n",
        "batch_size = 32\n",
        "\n",
        "train_dataset = tf.data.experimental.make_csv_dataset(\n",
        "    train_dataset_fp,\n",
        "    batch_size,\n",
        "    column_names=column_names,\n",
        "    label_name=label_name,\n",
        "    num_epochs=1)\n",
        "\n",
        "features, labels = next(iter(train_dataset))\n",
        "\"\"\"\n",
        "print(features)\n",
        "plt.scatter(features['petal_length'],\n",
        "            features['sepal_length'],\n",
        "            c=labels,\n",
        "            cmap='viridis')\n",
        "\n",
        "plt.xlabel(\"Petal length\")\n",
        "plt.ylabel(\"Sepal length\")\n",
        "plt.show()\n",
        "\"\"\"\n",
        "def pack_features_vector(features, labels):\n",
        "  \"\"\"Pack the features into a single array.\"\"\"\n",
        "  features = tf.stack(list(features.values()), axis=1)\n",
        "  return features, labels\n",
        "train_dataset = train_dataset.map(pack_features_vector)\n",
        "features, labels = next(iter(train_dataset))\n",
        "#print(features[:5])\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.relu, input_shape=(4,)),  # input shape required\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(3)\n",
        "])\n",
        "predictions = model(features)\n",
        "#predictions[:5]\n",
        "tf.nn.softmax(predictions[:5])\n",
        "print(\"Prediction: {}\".format(tf.argmax(predictions, axis=1)))\n",
        "print(\"    Labels: {}\".format(labels))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: [0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 0 1 1 1 1 1 0 1 0 1 0]\n",
            "    Labels: [0 1 0 2 0 1 0 0 2 2 0 2 0 2 0 0 1 2 0 1 0 0 2 1 2 2 2 0 2 0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u681mWic2His",
        "colab_type": "text"
      },
      "source": [
        "Our design of loss function is the distance between the distribution of errors and the continuous target distribution which can be Gaussian or Delta. Given that Delta is meaningless beyound integral, andt its integral, which is a step function, is dicontinuous. Let's consider Normal distribution. Normal distribution is much nicer. Actually, its density is infinitely differetiable with a very nice form:\n",
        "\n",
        "![alt text](http://i64.tinypic.com/2461h5y.png)    where ![alt text](http://i66.tinypic.com/j6lruh.jpg) is the density function for ![alt text](http://i68.tinypic.com/k1yp9i.png)\n",
        "\n",
        "-------------------------------------------------------------------------------------------------------\n",
        "Let's give up on calculating the differenation of Normal pdf.\n",
        "\n",
        "\n",
        "Thanks for [Shangkun](https://github.com/polossk)'s help, I will use kernel method here, more specifically, MMD ([Maximum Mean Divergence](https://stats.stackexchange.com/questions/276497/maximum-mean-discrepancy-distance-distribution)), to calculate the similarity between the distribution of the sample, and the target distribution. This method uses large size of samples to approximiate the target distribution. Compared to methods such as fitting parametric distribution, curve fitting,  using MMD here has several advantage:\n",
        "\n",
        "\n",
        "*   Allows samples of different size\n",
        "*   differentiable\n",
        "*   easy to calculate\n",
        "*   no assumption for distribution or polynomial curve\n",
        "*   no hyper-parameter, flexible for different batch size and good for reproducibility\n",
        "*   avoid dealing with overfitting\n",
        "\n",
        "The specific kernel function I used here is:\n",
        "\n",
        "![alt text](http://i65.tinypic.com/25ji4w7.png)\n",
        "\n",
        "\n",
        "To illustate this method makes sense, an example is show below, you can see the distributions of `b` and `c` are more similar than those of `a` and `c`, correspondingly, you can see the MMD of  `b` and `c` is smaller than that of `a` and `c`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrV1Ypqf7KuR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "976583e1-6e21-480a-e604-d7f2ede3e1e8"
      },
      "source": [
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "def MMD1d(x1, x2): # a and b are lists of aribiturary lengths\n",
        "  dis = sum([x**2 for x in x1])/len(x1) - sum([x**2 for x in x2])/len(x2)\n",
        "  return dis**2\n",
        "\n",
        "a, b, c = [-40, -40, -35, 40, 35, 40], [-10, -5, -15, -20,2, 5, 10], [-1,-6,-4,-1, 0, 2, 4, 1, 3, 2, 0, 8]\n",
        "print(f'a:{a} b:{b} c:{c}', '\\nMMD1d(a, c):%.4f.   MMD1d(b, c):%8.4f'%(MMD1d(a, c),MMD1d(b, c)))\n",
        "\n",
        "a_N, a_bins, a_patches = plt.hist(np.array(a), 30, ec=\"k\")\n",
        "b_N, b_bins, b_patches = plt.hist(np.array(b), 30, ec=\"k\")\n",
        "c_N, c_bins, c_patches = plt.hist(np.array(c), 30, ec=\"k\")\n",
        "cmap = plt.get_cmap('jet')\n",
        "for i in range(30):\n",
        "  a_patches[i].set_facecolor(cmap(0.25))\n",
        "for i in range(30):\n",
        "  b_patches[i].set_facecolor(cmap(0.4))\n",
        "for i in range(30):\n",
        "  c_patches[i].set_facecolor(cmap(0.8))\n",
        "handles = [Rectangle((0,0),1,1,color=c,ec=\"k\") for c in [cmap(0.25),cmap(0.4), cmap(0.8)]]\n",
        "lab= [\"a\",\"b\", \"c\"]\n",
        "plt.legend(handles, lab)\n",
        "plt.xlabel(\"x\", fontsize=16)  \n",
        "plt.ylabel(\"count\", fontsize=16)\n",
        "plt.show()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a:[-40, -40, -35, 40, 35, 40] b:[-10, -5, -15, -20, 2, 5, 10] c:[-1, -6, -4, -1, 0, 2, 4, 1, 3, 2, 0, 8] \n",
            "MMD1d(a, c):2138418.7778.   MMD1d(b, c):12747.4853\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEPCAYAAACDTflkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGS4iAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4tr7szgB1mZ",
        "colab_type": "text"
      },
      "source": [
        "The partial derivative of MMD w.r.t  ![alt text](http://i67.tinypic.com/v4wmfo.png) is:\n",
        "\n",
        "![alt text](http://i68.tinypic.com/2rnh4s3.png)\n",
        "\n",
        "Just for record, my original loss function is designed as below, the grads will return a list of 6 `None`s for 3 layers model. The reason is that the original loss function is not differentiable. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUgOlm5ZFatw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "b9a283b9-7b25-4358-c5d0-cf00d6a0abf2"
      },
      "source": [
        "import scipy.stats\n",
        "\n",
        "def get_distance_between_samples_and_distribution(errors, if_plot = 1, n_bins = 5):\n",
        "  def get_middle(x):\n",
        "    xMid = np.zeros(x.shape[0]//2)\n",
        "    for i in range(xMid.shape[0]):\n",
        "      xMid[i] = 0.5*(x[2*i]+x[2*i+1])\n",
        "    return xMid\n",
        "\n",
        "  bins, edges = np.histogram(errors, n_bins, normed=1)\n",
        "  left,right = edges[:-1],edges[1:]\n",
        "  X = np.array([left,right]).T.flatten()\n",
        "  Y = np.array([bins,bins]).T.flatten()\n",
        "  X_middle = get_middle(X)\n",
        "  Y_middle = get_middle(Y)\n",
        "  distance = []\n",
        "  for i in range(X_middle.shape[0]):\n",
        "    dis = np.square(scipy.stats.norm.pdf(X_middle[i])- Y_middle[i])\n",
        "    distance.append(dis)\n",
        "  distance2 = np.power(distance, 2)\n",
        "  \n",
        "  return sum(distance2)/len(distance2)\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "def loss(model, x, y):\n",
        "  y_ = model(x)\n",
        "  losses = []\n",
        "  # y_.shape is (batch_size, 3)\n",
        "  for i in range(y.shape[0]):\n",
        "    loss = loss_object(y_true=y[i], y_pred=y_[i])\n",
        "    losses.append(loss)\n",
        "  dis = get_distance_between_samples_and_distribution(losses, if_plot = 0)\n",
        "  return tf.convert_to_tensor(dis, dtype=np.float32)\n",
        "\n",
        "def grad(model, inputs, targets):\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(model.trainable_variables)\n",
        "    loss_value = loss(model, inputs, targets)\n",
        "  return loss_value, tape.gradient(loss_value, model.trainable_variables)\n",
        "\n",
        "loss_value, grads = grad(model, features, labels)\n",
        "print(\"loss_value:\",loss_value)\n",
        "print(\"type(loss_value):\", type(loss_value))\n",
        "print(\"\\ngrads:\", grads)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss_value: tf.Tensor(0.0031982895, shape=(), dtype=float32)\n",
            "type(loss_value): <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "\n",
            "grads: [None, None, None, None, None, None]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Passing `normed=True` on non-uniform bins has always been broken, and computes neither the probability density function nor the probability mass function. The result is only correct if the bins are uniform, when density=True will produce the same result anyway. The argument will be removed in a future version of numpy.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YU-qgWnJdCe",
        "colab_type": "text"
      },
      "source": [
        "As written before, the MMD function is differentiable and therefore can be used to train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RrwnLMHfqsl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ff813354-9fb5-4690-c7eb-b626ea98e6d9"
      },
      "source": [
        "def get_MMD_norm(errors, sigma=0.1): # sigma is the standard deviation of our target distribution, it keeps updating to smaller value during training\n",
        "  x2 = np.random.normal(0, sigma, 100)\n",
        "  loss = MMD1d(errors, x2)\n",
        "  return loss\n",
        "\n",
        "def loss(model, x, y):\n",
        "  y_ = model(x) # y_.shape is (batch_size, 3) for Iris dataset\n",
        "  losses = []\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  for i in range(y.shape[0]):\n",
        "    loss = loss_object(y_true=y[i], y_pred=y_[i])\n",
        "    losses.append(loss)\n",
        "  loss = get_MMD_norm(losses)\n",
        "  return tf.convert_to_tensor(loss, dtype=np.float32)\n",
        "\n",
        "def grad(model, inputs, targets):\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(model.trainable_variables)\n",
        "    loss_value = loss(model, inputs, targets)\n",
        "  return loss_value, tape.gradient(loss_value, model.trainable_variables)\n",
        "\n",
        "loss_value, grads = grad(model, features, labels)\n",
        "print(\"loss_value:\",loss_value)\n",
        "print(\"type(loss_value):\", type(loss_value))\n",
        "print(\"\\ngrads:\", grads)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss_value: tf.Tensor(106.67751, shape=(), dtype=float32)\n",
            "type(loss_value): <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "\n",
            "grads: [<tf.Tensor: id=5117591, shape=(4, 10), dtype=float32, numpy=\n",
            "array([[   0.       , -224.07385  ,  230.50374  ,  115.50677  ,\n",
            "           0.       ,  316.0283   ,  138.18106  ,  258.49985  ,\n",
            "        -341.2846   ,    2.937387 ],\n",
            "       [   0.       , -102.72963  ,  105.12328  ,   52.608864 ,\n",
            "           0.       ,  144.8313   ,   62.99159  ,  118.09052  ,\n",
            "        -156.2037   ,    0.7131056],\n",
            "       [   0.       , -183.04773  ,  190.17044  ,   95.37037  ,\n",
            "           0.       ,  258.53378  ,  113.09698  ,  212.4229   ,\n",
            "        -279.49216  ,    4.498368 ],\n",
            "       [   0.       ,  -65.19074  ,   67.96276  ,   34.075924 ,\n",
            "           0.       ,   92.12941  ,   43.447094 ,   75.80335  ,\n",
            "         -99.616974 ,    1.8641778]], dtype=float32)>, <tf.Tensor: id=5117590, shape=(10,), dtype=float32, numpy=\n",
            "array([  0.        , -32.721172  ,  33.490913  ,  16.754986  ,\n",
            "         0.        ,  46.131058  ,  20.309673  ,  37.617832  ,\n",
            "       -49.757378  ,   0.23584916], dtype=float32)>, <tf.Tensor: id=5117588, shape=(10, 10), dtype=float32, numpy=\n",
            "array([[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
            "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
            "         0.0000000e+00,  0.0000000e+00],\n",
            "       [ 1.1829005e+02,  0.0000000e+00,  3.1812162e+01,  2.7948894e-02,\n",
            "        -5.9592686e+01,  0.0000000e+00,  1.7685044e+00,  0.0000000e+00,\n",
            "         0.0000000e+00,  0.0000000e+00],\n",
            "       [ 3.0671429e+02,  0.0000000e+00,  8.2629837e+01,  8.3108023e-02,\n",
            "        -1.5541805e+02,  0.0000000e+00,  5.2718105e+00,  0.0000000e+00,\n",
            "         0.0000000e+00,  0.0000000e+00],\n",
            "       [ 5.3322033e+01,  0.0000000e+00,  1.4213736e+01,  0.0000000e+00,\n",
            "        -2.6073483e+01,  0.0000000e+00,  5.1137572e-04,  0.0000000e+00,\n",
            "         0.0000000e+00,  0.0000000e+00],\n",
            "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
            "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
            "         0.0000000e+00,  0.0000000e+00],\n",
            "       [ 3.9061566e+02,  0.0000000e+00,  1.0461395e+02,  3.6978506e-02,\n",
            "        -1.9406421e+02,  0.0000000e+00,  2.7593975e+00,  0.0000000e+00,\n",
            "         0.0000000e+00,  0.0000000e+00],\n",
            "       [ 1.3608975e+01,  0.0000000e+00,  3.6345675e+00,  0.0000000e+00,\n",
            "        -6.6976724e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
            "         0.0000000e+00,  0.0000000e+00],\n",
            "       [ 3.9012961e+02,  0.0000000e+00,  1.0466981e+02,  5.7222206e-02,\n",
            "        -1.9498485e+02,  0.0000000e+00,  3.9318209e+00,  0.0000000e+00,\n",
            "         0.0000000e+00,  0.0000000e+00],\n",
            "       [ 2.3003476e+02,  0.0000000e+00,  6.2097919e+01,  7.4612767e-02,\n",
            "        -1.1734893e+02,  0.0000000e+00,  4.6943364e+00,  0.0000000e+00,\n",
            "         0.0000000e+00,  0.0000000e+00],\n",
            "       [ 3.6627521e+02,  0.0000000e+00,  9.8179497e+01,  4.4575244e-02,\n",
            "        -1.8249843e+02,  0.0000000e+00,  3.1652334e+00,  0.0000000e+00,\n",
            "         0.0000000e+00,  0.0000000e+00]], dtype=float32)>, <tf.Tensor: id=5117586, shape=(10,), dtype=float32, numpy=\n",
            "array([ 7.6144951e+01,  0.0000000e+00,  2.0516069e+01,  1.6749872e-02,\n",
            "       -3.8598915e+01,  0.0000000e+00,  1.3493444e+00,  0.0000000e+00,\n",
            "        0.0000000e+00,  0.0000000e+00], dtype=float32)>, <tf.Tensor: id=5117584, shape=(10, 3), dtype=float32, numpy=\n",
            "array([[ 7.5863091e+01,  4.1302313e+02, -4.8888620e+02],\n",
            "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
            "       [ 5.6296379e+01,  3.1066107e+02, -3.6695749e+02],\n",
            "       [-1.1845173e-03,  9.4325439e-04,  2.4126255e-04],\n",
            "       [ 5.6754059e+01,  3.3155347e+02, -3.8830750e+02],\n",
            "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
            "       [-5.1024950e-01,  4.0809643e-01,  1.0215306e-01],\n",
            "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
            "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
            "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00]], dtype=float32)>, <tf.Tensor: id=5117582, shape=(3,), dtype=float32, numpy=array([ 10.873512,  65.698555, -76.57207 ], dtype=float32)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wX1HRP44bnY2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "59c45a33-07be-4cfd-c661-f1665718b21b"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "print(\"Step: {}, Initial Loss: {}\".format(optimizer.iterations.numpy(),\n",
        "                                          loss_value.numpy()))\n",
        "\n",
        "optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "print(\"Step: {},         Loss: {}\".format(optimizer.iterations.numpy(),\n",
        "                                          loss(model, features, labels).numpy()))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step: 0, Initial Loss: 106.6775131225586\n",
            "Step: 1,         Loss: 40.6317024230957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AIgulGRUhpto",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "d155178b-5be5-45c2-c392-c23acd22c624"
      },
      "source": [
        "## Note: Rerunning this cell uses the same model variables\n",
        "\n",
        "# keep results for plotting\n",
        "train_loss_results = []\n",
        "train_accuracy_results = []\n",
        "\n",
        "num_epochs = 200\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "  epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "  # Training loop - using batches of 32\n",
        "  for x, y in train_dataset:\n",
        "    # Optimize the model\n",
        "    loss_value, grads = grad(model, x, y)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Track progress\n",
        "    epoch_loss_avg(loss_value)  # add current batch loss\n",
        "    # compare predicted label to actual label\n",
        "    epoch_accuracy(y, model(x))\n",
        "\n",
        "  # end epoch\n",
        "  train_loss_results.append(epoch_loss_avg.result())\n",
        "  train_accuracy_results.append(epoch_accuracy.result())\n",
        "\n",
        "  if epoch % 50 == 0:\n",
        "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
        "                                                                epoch_loss_avg.result(),\n",
        "                                                                epoch_accuracy.result()))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000: Loss: 22.260, Accuracy: 35.000%\n",
            "Epoch 050: Loss: 0.128, Accuracy: 89.167%\n",
            "Epoch 100: Loss: 0.038, Accuracy: 99.167%\n",
            "Epoch 150: Loss: 0.017, Accuracy: 99.167%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "agjvNd2iUGFn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "3988bae7-3ef2-4719-f41f-1cd135ea88a0"
      },
      "source": [
        "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
        "fig.suptitle('Training Metrics')\n",
        "\n",
        "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
        "axes[0].plot(train_loss_results)\n",
        "\n",
        "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
        "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
        "axes[1].plot(train_accuracy_results)\n",
        "plt.show()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtgAAAIdCAYAAAAH9goCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nAX834PJxWO",
        "colab_type": "text"
      },
      "source": [
        "To better leverage the design of loss function, I will use callbacks to detect the learning progress, once the loss stopped decreasing for 10 epochs, instead of early stopping, I will shrink the standard deviation of the target distribution by half. Now, let's write the callbacks for tracking loss history."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ps3_9dJ3Lodk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "ba7f89de-b7e0-4a6a-d8c0-417dbcfcf43c"
      },
      "source": [
        "test_url = \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\"\n",
        "\n",
        "test_fp = tf.keras.utils.get_file(fname=os.path.basename(test_url),\n",
        "                                  origin=test_url)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\n",
            "\r8192/573 [============================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SRMWCu30bnxH",
        "colab": {}
      },
      "source": [
        "test_dataset = tf.data.experimental.make_csv_dataset(\n",
        "    test_fp,\n",
        "    batch_size,\n",
        "    column_names=column_names,\n",
        "    label_name='species',\n",
        "    num_epochs=1,\n",
        "    shuffle=False)\n",
        "\n",
        "test_dataset = test_dataset.map(pack_features_vector)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Tw03-MK1cYId",
        "colab": {}
      },
      "source": [
        "test_accuracy = tf.keras.metrics.Accuracy()\n",
        "\n",
        "for (x, y) in test_dataset:\n",
        "  logits = model(x)\n",
        "  prediction = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
        "  test_accuracy(prediction, y)\n",
        "\n",
        "print(\"Test set accuracy: {:.3%}\".format(test_accuracy.result()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uNwt2eMeOane",
        "colab": {}
      },
      "source": [
        "tf.stack([y,prediction],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kesTS5Lzv-M2",
        "colab": {}
      },
      "source": [
        "predict_dataset = tf.convert_to_tensor([\n",
        "    [5.1, 3.3, 1.7, 0.5,],\n",
        "    [5.9, 3.0, 4.2, 1.5,],\n",
        "    [6.9, 3.1, 5.4, 2.1]\n",
        "])\n",
        "\n",
        "predictions = model(predict_dataset)\n",
        "\n",
        "for i, logits in enumerate(predictions):\n",
        "  class_idx = tf.argmax(logits).numpy()\n",
        "  p = tf.nn.softmax(logits)[class_idx]\n",
        "  name = class_names[class_idx]\n",
        "  print(\"Example {} prediction: {} ({:4.1f}%)\".format(i, name, 100*p))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JliO3dfQRcbg",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}